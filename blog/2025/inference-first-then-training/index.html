<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> From Song &amp; Zhou - Ideas in Inference-time Scaling can Benefit Generative Pre-training Algorithms | Toan Khanh Nguyen </title> <meta name="author" content="Toan Khanh Nguyen"> <meta name="description" content="how Inference-time Scaling can Benefit Generative Pre-training Algorithms"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nktoan.github.io/blog/2025/inference-first-then-training/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Toan</span> Khanh Nguyen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">From Song &amp; Zhou - Ideas in Inference-time Scaling can Benefit Generative Pre-training Algorithms</h1> <p class="post-meta"> Created on May 04, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> Â  Â· Â  <a href="/blog/tag/inference"> <i class="fa-solid fa-hashtag fa-sm"></i> inference</a> Â  <a href="/blog/tag/time"> <i class="fa-solid fa-hashtag fa-sm"></i> time</a> Â  <a href="/blog/tag/scaling"> <i class="fa-solid fa-hashtag fa-sm"></i> scaling</a> Â  <a href="/blog/tag/n"> <i class="fa-solid fa-hashtag fa-sm"></i> n</a> Â  <a href="/blog/tag/generative"> <i class="fa-solid fa-hashtag fa-sm"></i> generative</a> Â  <a href="/blog/tag/pre-training"> <i class="fa-solid fa-hashtag fa-sm"></i> pre-training</a> Â  <a href="/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> algorithms</a> Â  Â· Â  <a href="/blog/category/sample-posts"> <i class="fa-solid fa-tag fa-sm"></i> sample-posts</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Yesterday, I came across an insightful article by Jiaming Song and Linqi Zhou, both are leading researchers pushing the boundaries of generative modelling. This blog post summarises their main arguments, explores some key concepts, and includes my own reflections on how their work may shape the future of generative pre-training.</p> <hr> <h2 id="-tldr">ğŸ” TL;DR</h2> <ul> <li> <p><strong>Main Idea</strong>: Inference-time efficiencyâ€”scaling along <em>sequence length</em> (in LLMs) and <em>refinement steps</em> (in diffusion models)â€”should <em>inform</em> the <em>design of generative pre-training algorithms</em>.</p> </li> <li> <p><strong>Highlighted Contribution</strong>: Their recent work, <strong>Inductive Moment Matching (IMM)</strong>, introduces a stable, single-stage generative method that outperforms traditional diffusion models in sample quality while also improving inference efficiency. The approach is inspired by a fixed-DDIM inference algorithm.</p> </li> </ul> <hr> <h2 id="-key-insights">ğŸ§  Key insights</h2> <h3 id="1-breaking-the-stagnation-in-generative-models">1. Breaking the Stagnation in Generative Models</h3> <ul> <li> <strong>Observation</strong>: Discrete data is dominated by <em>autoregressive models</em>; continuous data by <em>diffusion models</em>.</li> <li> <strong>Problem</strong>: This paradigm has reached a plateauâ€”limiting exploration into new architectures.</li> </ul> <h3 id="2-two-principles-for-future-generative-algorithms">2. Two Principles for Future Generative Algorithms</h3> <p>To build more practical and scalable generative pre-training algorithms:</p> <ul> <li> <strong>(i)</strong> <strong>Design to scale at inference time</strong> in both <strong>sequence length</strong> and <strong>refinement steps</strong>.</li> <li> <strong>(ii)</strong> <strong>Start with the inference algorithm</strong>, and design training to optimise that inference (i.e., <em>think about how the model will generate</em> before you train it).</li> </ul> <h3 id="3-mixed-modality-generation">3. Mixed-Modality Generation</h3> <ul> <li>The inference-first mindset might be particularly valuable in designing <strong>unified models for mixed modalities</strong> (e.g., image + text + audio).</li> <li> <strong>Question posed</strong>: Can we invent <em>scalable, efficient</em> pre-training methods for such settings?</li> </ul> <hr> <h2 id="-scalability-matrix-of-generative-models">ğŸ“Š Scalability Matrix of Generative Models</h2> <table> <thead> <tr> <th><strong>Scalability</strong></th> <th><strong>Methods</strong></th> </tr> </thead> <tbody> <tr> <td>âŒ Sequence Length<br>âŒ Refinement Steps</td> <td>VAE, GAN, Normalizing Flows</td> </tr> <tr> <td>âœ… Sequence Length<br>âŒ Refinement Steps</td> <td>GPT, PixelCNN, MaskGiT, VAR</td> </tr> <tr> <td>âŒ Sequence Length<br>âœ… Refinement Steps</td> <td>Diffusion, Energy-based Models, Consistency Models, Parallel Equation Solving</td> </tr> <tr> <td>âœ… Sequence Length<br>âœ… Refinement Steps <em>(Outer: Sequence)</em> </td> <td>AR-Diffusion, Rolling Diffusion, MAR, Blockwise Parallel Decoding</td> </tr> <tr> <td>âœ… Sequence Length<br>âœ… Refinement Steps <em>(Outer: Refinement)</em> </td> <td>Autoregressive Distribution Smoothing</td> </tr> </tbody> </table> <hr> <h2 id="-examples-of-fixing-the-inference-algorithm">ğŸ›  Examples of Fixing the Inference Algorithm</h2> <p>Two notable strategies where inference design influences training:</p> <ul> <li> <p><strong>DDIM Sampler</strong>: Uses future-time conditioning to refine generation trajectories, for example by modeling $v_{\theta}(x_t, t, s)$ where $s$ is a future time step.</p> </li> <li> <p><strong>Multi-token Prediction</strong>: Often assumes conditional independence, which simplifies inference but may limit expressiveness.</p> </li> </ul> <hr> <h2 id="-my-thoughts-and-takeaways">ğŸ’­ My Thoughts and Takeaways</h2> <ul> <li> <p>Generative algorithms are fundamentally about predicting the next X. Here, X could be the next token in language models (LLMs), the next sample at a future timestep in diffusion models, or the next scale in methods like VAR (NeurIPS 2024). Recently, a paper titled â€œNext-X Predictionâ€ proposed a generalisation of this idea, unifying various forms of Xâ€”including tokens, cells, subsamples, images, and scalesâ€”under a single framework. From a slightly different perspective, models like AlphaEvolve can be viewed as predicting the next program or algorithm, while GFlowNets or Mamba correspond to next action-state prediction. MCP, on the other hand, focuses on selecting the next action over a planning horizon.</p> </li> <li> <p>In essence, all generative algorithms share one core principle: predicting the next one.</p> </li> <li> <p>To design new generative algorithms, we can think in terms of â€œnext-X<em>-predictionâ€â€”where X</em> is any unit of generationâ€”and explore whether the approach scales well across dimensions such as time, resolution, or abstraction. This idea can also be extended to higher levels, such as predicting at the distributional level (e.g., cluster or segment) or at the probabilistic level (e.g., generating 80% of X and 20% of Y).</p> </li> <li> <p>What about discriminative algorithms? Yann LeCun often champions these over generative ones. However, I believe they canâ€”and shouldâ€”be integrated. Discriminative insights (e.g., object relationships in images or structural patterns in text) can enrich generative models by informing the structure and coherence of the next-X* prediction. This combination will be very helpful in the multimodal setting.</p> </li> <li> <p>My thought is that for text-image models, X* can be smartly designed so that the text must be aligned with the image throughout the generation process.</p> </li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Toan Khanh Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/plotly.js@3.0.1/dist/plotly.min.js" integrity="sha256-oy6Be7Eh6eiQFs5M7oXuPxxm9qbJXEtTpfSI93dW16Q=" crossorigin="anonymous"></script> <script defer src="/assets/js/plotly-setup.js?5e81fc889064852664784cb29c0d6970" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>